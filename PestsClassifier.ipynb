{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chete\\AppData\\Local\\Temp\\ipykernel_19916\\791244354.py:37: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython.display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "# %% [IMPORTS AND SETUP]\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Minimiza mensajes de advertencia de TF\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import (Dense, Activation, Dropout, Conv2D, \n",
    "                                     MaxPooling2D, BatchNormalization, Flatten)\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time\n",
    "import cv2 as cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "print ('modules loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# UTILIDADES SIMPLIFICADAS\n",
    "# -------------------------------------------------\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def preview_batch(generator, max_imgs: int = 25) -> None:\n",
    "    \"\"\"\n",
    "    Muestra hasta `max_imgs` imágenes del siguiente batch que\n",
    "    entrega un `ImageDataGenerator`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    generator : keras.utils.Sequence\n",
    "        Generador que produce pares (images, labels).\n",
    "    max_imgs : int, optional\n",
    "        Límite de imágenes a visualizar (por defecto 25).\n",
    "    \"\"\"\n",
    "    images, labels = next(generator)          # 1 batch\n",
    "    class_names = list(generator.class_indices)   # orden Keras\n",
    "\n",
    "    n = min(len(images), max_imgs)\n",
    "    cols = 5\n",
    "    rows = int(np.ceil(n / cols))\n",
    "    plt.figure(figsize=(cols * 3, rows * 3))\n",
    "\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(rows, cols, i + 1)\n",
    "        ax.imshow(images[i] / 255.0)          # simple normalización\n",
    "        label_idx = int(np.argmax(labels[i]))\n",
    "        ax.set_title(class_names[label_idx], fontsize=9)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_first_image_per_class(root_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Busca *una* imagen llamada ``1.jpg`` dentro de cada subcarpeta\n",
    "    de ``root_dir`` y la muestra. Cada subcarpeta se considera\n",
    "    una clase.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root_dir : str\n",
    "        Carpeta con subdirectorios de clases.\n",
    "    \"\"\"\n",
    "    subdirs = sorted(d for d in os.listdir(root_dir)\n",
    "                     if os.path.isdir(os.path.join(root_dir, d)))\n",
    "\n",
    "    cols = 5\n",
    "    rows = int(np.ceil(len(subdirs) / cols))\n",
    "    plt.figure(figsize=(cols * 3.5, rows * 3.5))\n",
    "\n",
    "    for i, cls in enumerate(subdirs):\n",
    "        img_path = os.path.join(root_dir, cls, \"1.jpg\")\n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "        ax = plt.subplot(rows, cols, i + 1)\n",
    "        ax.imshow(plt.imread(img_path))\n",
    "        ax.set_title(cls, fontsize=9)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def cprint(msg: str, *, color: str = \"green\") -> None:\n",
    "    \"\"\"\n",
    "    Imprime `msg` en color ANSI sencillo. Usar sólo nombres\n",
    "    básicos ('red', 'green', 'yellow', 'blue', 'cyan').\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    msg : str\n",
    "        Texto a imprimir.\n",
    "    color : str, optional\n",
    "        Color solicitado (por defecto 'green').\n",
    "    \"\"\"\n",
    "    colors = {\n",
    "        \"red\":    \"31\",\n",
    "        \"green\":  \"32\",\n",
    "        \"yellow\": \"33\",\n",
    "        \"blue\":   \"34\",\n",
    "        \"cyan\":   \"36\"\n",
    "    }\n",
    "    code = colors.get(color.lower(), \"0\")\n",
    "    print(f\"\\033[{code}m{msg}\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# FLEXIBLE L‑RATE ASSISTANT  (drop‑in reemplazo de la antigua clase LRA)\n",
    "# -----------------------------------------------------------------------------\n",
    "class FlexLRA(Callback):\n",
    "    \"\"\"Callback avanzado de *Learning‑Rate Adaptation* (mantiene **TODAS** las\n",
    "    funciones del código original pero con una lógica más compacta).\n",
    "\n",
    "    Funcionalidades:\n",
    "    1. **Reduce** la *learning‑rate* según *patience* (Plateau LR‑Scheduler).\n",
    "    2. **Early‑stop** después de *stop_patience* reducciones consecutivas sin mejora.\n",
    "    3. **Restauración de pesos** del mejor epoch al terminar o al activar *dwell*.\n",
    "    4. **Cambio de métrica**: empieza monitorizando *training accuracy*; cuando\n",
    "       esta supera *threshold* pasa a vigilar *val_loss*.\n",
    "    5. **Dwell**: si una época no mejora, recupera los pesos del mejor epoch\n",
    "       antes de continuar (opcional).\n",
    "    6. **ask_epoch**: en la época indicada (y sucesivas) pregunta al usuario si\n",
    "       desea *H*alt, *T*une (activar *fine‑tuning*) o cuántas epochs extra correr.\n",
    "    7. **CSV logging** (opcional) con las estadísticas de cada epoch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : tf.keras.Model\n",
    "        Modelo compilado que se entrena (se pasa automáticamente al instanciar).\n",
    "    base_model : tf.keras.Model | None\n",
    "        Sub‑modelo que puede congelarse y luego habilitarse para *fine‑tuning*.\n",
    "        Si es *None* se ignoran las opciones *T*.\n",
    "    patience : int\n",
    "        Épocas sin mejora antes de reducir LR.\n",
    "    stop_patience : int\n",
    "        Nº de reducciones permitidas sin mejora antes de detener entrenamiento.\n",
    "    threshold : float\n",
    "        Accuracy de entrenamiento a partir de la cual se cambia el monitor a\n",
    "        *val_loss*.\n",
    "    factor : float\n",
    "        Multiplicador de LR (lr *= factor) cuando se reduce.\n",
    "    dwell : bool\n",
    "        Si *True*, tras una época sin mejora se restauran los pesos previos.\n",
    "    batches : int\n",
    "        Cuántos batches hay en cada epoch (solo para print de progreso).\n",
    "    initial_epoch, epochs : int\n",
    "        Contadores usados solo para mostrar información formateada.\n",
    "    ask_epoch : int | None\n",
    "        Epoch a partir de la cual se lanza la consulta interactiva (o *None*).\n",
    "    csv_path : str | None\n",
    "        Ruta base donde guardar el *log* CSV (se añade timestamp).\n",
    "    verbose : int (0/1)\n",
    "        1 imprime mensajes en consola; 0 los silencia.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        model: tf.keras.Model,\n",
    "        base_model: Optional[tf.keras.Model],\n",
    "        patience: int = 1,\n",
    "        stop_patience: int = 3,\n",
    "        threshold: float = 0.90,\n",
    "        factor: float = 0.5,\n",
    "        dwell: bool = True,\n",
    "        batches: int,\n",
    "        initial_epoch: int,\n",
    "        epochs: int,\n",
    "        ask_epoch: Optional[int] = None,\n",
    "        csv_path: Optional[str] = None,\n",
    "        verbose: int = 1,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # ajustes de usuario\n",
    "        self.base_model = base_model\n",
    "        self.patience = patience\n",
    "        self.stop_patience = stop_patience\n",
    "        self.threshold = threshold\n",
    "        self.factor = factor\n",
    "        self.dwell = dwell\n",
    "        self.batches = batches\n",
    "        self.init_epoch = initial_epoch\n",
    "        self.total_epochs = epochs\n",
    "        self.ask_epoch = ask_epoch\n",
    "        self.ask_initial = ask_epoch\n",
    "        self.csv_path = csv_path\n",
    "        self.verbose = bool(verbose)\n",
    "\n",
    "        # estado interno\n",
    "        self._no_improve: int = 0          # epochs sin mejora\n",
    "        self._lr_cuts: int = 0             # reducciones realizadas\n",
    "        self._best_epoch: int = 0\n",
    "        self._best_weights = model.get_weights()\n",
    "        self._best_train_acc = 0.0\n",
    "        self._best_val_loss = np.inf\n",
    "        self._log: Dict[str, List] = {\n",
    "            k: [] for k in [\n",
    "                \"epoch\", \"loss\", \"train_acc\", \"val_loss\", \"val_acc\",\n",
    "                \"lr_now\", \"lr_next\", \"monitor\", \"%improv\", \"sec\"\n",
    "            ]\n",
    "        }\n",
    "        self._start: float = 0.0\n",
    "\n",
    "    # -------------------------------------------- HOOKS --------------------------------------------\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self._start = time.time()\n",
    "        if self.verbose:\n",
    "            mode = \"trainable\" if (self.base_model and self.base_model.trainable) else \"frozen\"\n",
    "            print(f\"FlexLRA · start ({mode}) – monitoring accuracy ➜ val_loss (threshold={self.threshold})\")\n",
    "            header = (\"Ep  |  Loss   TrAcc   VLoss   VAcc   LR ➜ NextLR  Monitor  Δ%  Sec\")\n",
    "            print(header)\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if self.verbose:\n",
    "            acc = logs.get(\"accuracy\", 0) * 100\n",
    "            loss = logs.get(\"loss\", 0)\n",
    "            print(f\"\\rBatch {batch+1}/{self.batches}  acc={acc:5.2f}%  loss={loss:.4f}\", end=\"\")\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self._epoch_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):  # noqa: C901 – método largo pero lineal\n",
    "        # ------------------------------------------------------------------\n",
    "        # RECOPILAR MÉTRICAS BÁSICAS\n",
    "        t_loss: float = logs.get(\"loss\", 0.0)\n",
    "        t_acc: float = logs.get(\"accuracy\", 0.0)\n",
    "        v_loss: float = logs.get(\"val_loss\", np.inf)\n",
    "        v_acc: float = logs.get(\"val_accuracy\", 0.0)\n",
    "        lr_now: float = float(K.get_value(self.model.optimizer.lr))\n",
    "        lr_next: float = lr_now  # se actualizará si reducimos\n",
    "        duration = time.time() - self._epoch_start\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # SELECCIÓN DEL MONITOR Y CÁLCULO DEL % DE MEJORA\n",
    "        if t_acc < self.threshold:                            # fase 1 → monitor=accuracy\n",
    "            monitor, current, best = \"acc\", t_acc, self._best_train_acc\n",
    "        else:                                                 # fase 2 → monitor=val_loss (queremos minimizar)\n",
    "            monitor, current, best = \"val_loss\", v_loss, self._best_val_loss\n",
    "        if best in (0.0, np.inf):   # primera comparación\n",
    "            pct_improv = 0.0\n",
    "        else:\n",
    "            delta = (current - best) if monitor == \"acc\" else (best - current)\n",
    "            pct_improv = 100 * delta / (abs(best) + 1e-8)\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # ¿HAY MEJORA?\n",
    "        improved = (current > best) if monitor == \"acc\" else (current < best)\n",
    "        if improved:\n",
    "            # reset counters y guardar pesos\n",
    "            if monitor == \"acc\":\n",
    "                self._best_train_acc = current\n",
    "            else:\n",
    "                self._best_val_loss = current\n",
    "            self._best_epoch = epoch + 1\n",
    "            self._best_weights = self.model.get_weights()\n",
    "            self._no_improve = 0\n",
    "            self._lr_cuts = 0 if monitor == \"acc\" else self._lr_cuts  # solo reset en fase 1\n",
    "        else:\n",
    "            self._no_improve += 1\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # REDUCE LR SI CORRESPONDE\n",
    "        if self._no_improve >= self.patience:\n",
    "            lr_next = max(lr_now * self.factor, 1e-7)\n",
    "            K.set_value(self.model.optimizer.lr, lr_next)\n",
    "            self._no_improve = 0\n",
    "            self._lr_cuts += 1\n",
    "            # Dwell → restaurar mejores pesos\n",
    "            if self.dwell:\n",
    "                self.model.set_weights(self._best_weights)\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # EARLY STOP\n",
    "        if self._lr_cuts >= self.stop_patience:\n",
    "            if self.verbose:\n",
    "                print(f\"\\nEarly‑stop: {self.stop_patience} recortes de LR sin mejora • Restaurando epoch {self._best_epoch}.\")\n",
    "            self.model.stop_training = True\n",
    "            self.model.set_weights(self._best_weights)\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # LOG IMPRESO (una sola línea simple)\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f\"\\n{epoch+1:3d}/{self.total_epochs:3d}  \"\n",
    "                f\"{t_loss:.4f}  {t_acc*100:6.2f}%  \"\n",
    "                f\"{v_loss:.4f}  {v_acc*100:6.2f}%  \"\n",
    "                f\"{lr_now:7.1e} ➜ {lr_next:7.1e}  {monitor:>8s}  \"\n",
    "                f\"{pct_improv:+6.2f}%  {duration:4.1f}s\"\n",
    "            )\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # GUARDAR EN LOG interno → CSV opcional\n",
    "        self._log_epoch(epoch, t_loss, t_acc, v_loss, v_acc, lr_now, lr_next, monitor, pct_improv, duration)\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # INTERACCIÓN ASK_EPOCH\n",
    "        if self.ask_epoch and (epoch + 1) >= self.ask_epoch and not self.model.stop_training:\n",
    "            self._interactive_prompt(epoch)\n",
    "\n",
    "    # -------------------------------------------- AUX --------------------------------------------\n",
    "    def _log_epoch(self, ep, tl, ta, vl, va, lr_now, lr_next, mon, pct, sec):\n",
    "        self._log[\"epoch\"].append(ep + 1)\n",
    "        self._log[\"loss\"].append(tl)\n",
    "        self._log[\"train_acc\"].append(ta)\n",
    "        self._log[\"val_loss\"].append(vl)\n",
    "        self._log[\"val_acc\"].append(va)\n",
    "        self._log[\"lr_now\"].append(lr_now)\n",
    "        self._log[\"lr_next\"].append(lr_next)\n",
    "        self._log[\"monitor\"].append(mon)\n",
    "        self._log[\"%improv\"].append(pct)\n",
    "        self._log[\"sec\"].append(sec)\n",
    "\n",
    "        if self.csv_path:\n",
    "            out_dir = Path(self.csv_path)\n",
    "            out_dir.mkdir(parents=True, exist_ok=True)\n",
    "            ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "            pd.DataFrame(self._log).to_csv(out_dir / f\"log_{ts}.csv\", index=False)\n",
    "\n",
    "    def _interactive_prompt(self, epoch: int):  # 🛈 llamada sólo si ask_epoch está definido\n",
    "        prompt = (\n",
    "            \"\\n[FlexLRA] Epoch %d reached.  (H)alt | (T)une base_model | N (entero) más epochs: \"\n",
    "            % (epoch + 1)\n",
    "        )\n",
    "        ans = input(prompt).strip().lower()\n",
    "        if ans == \"h\":\n",
    "            self.model.stop_training = True\n",
    "            self.model.set_weights(self._best_weights)\n",
    "        elif ans == \"t\" and self.base_model is not None:\n",
    "            self.base_model.trainable = True\n",
    "            print(\"Fine‑tuning ACTIVADO – base_model.trainable = True\")\n",
    "        else:\n",
    "            try:\n",
    "                extra = int(ans)\n",
    "                self.ask_epoch = epoch + 1 + extra\n",
    "                self._no_improve = 0\n",
    "                self._lr_cuts = 0\n",
    "            except ValueError:\n",
    "                print(\"Entrada ignorada. Continuando…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# PLOTTING · EVALUATION · MODEL SAVING  (versión depurada)\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "# 1) CURVAS DE ENTRENAMIENTO\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "def plot_history(history, start: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    Dibuja pérdidas y accuracies de train/val a partir de `history`\n",
    "    (objeto devuelto por `model.fit`).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : keras.callbacks.History\n",
    "    start : int, optional\n",
    "        Nº de epoch inicial (útil si continúas entrenamiento).\n",
    "    \"\"\"\n",
    "    tr_acc = history.history[\"accuracy\"]\n",
    "    tr_loss = history.history[\"loss\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    epochs = range(start + 1, start + len(tr_acc) + 1)\n",
    "\n",
    "    best_vl = int(np.argmin(val_loss)) + start + 1\n",
    "    best_va = int(np.argmax(val_acc)) + start + 1\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, tr_loss, label=\"train\")\n",
    "    plt.plot(epochs, val_loss, label=\"val\")\n",
    "    plt.scatter(best_vl, val_loss[best_vl - start - 1], color=\"red\")\n",
    "    plt.title(\"Loss\");  plt.xlabel(\"epoch\");  plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, tr_acc, label=\"train\")\n",
    "    plt.plot(epochs, val_acc, label=\"val\")\n",
    "    plt.scatter(best_va, val_acc[best_va - start - 1], color=\"red\")\n",
    "    plt.title(\"Accuracy\");  plt.xlabel(\"epoch\");  plt.ylabel(\"acc\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "# 2) EVALUACIÓN DETALLADA\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "def evaluate_predictions(\n",
    "    generator: Sequence,\n",
    "    preds: np.ndarray,\n",
    "    show_errors: int = 0\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Imprime accuracy, ejemplos de errores, matriz de confusión\n",
    "    y classification report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    generator : keras.utils.Sequence\n",
    "        Generador usado para obtener las etiquetas reales.\n",
    "    preds : np.ndarray\n",
    "        Probabilidades predichas (output de `model.predict`).\n",
    "    show_errors : int, optional\n",
    "        Nº de errores a listar. 0 = no mostrar.\n",
    "    \"\"\"\n",
    "    y_true = generator.labels\n",
    "    file_list = generator.filenames\n",
    "    idx_to_cls = {v: k for k, v in generator.class_indices.items()}\n",
    "\n",
    "    y_pred = np.argmax(preds, axis=1)\n",
    "    probs   = preds[np.arange(len(preds)), y_pred]\n",
    "\n",
    "    # Estadísticas\n",
    "    mismatches = y_pred != y_true\n",
    "    err_idx    = np.where(mismatches)[0]\n",
    "    acc = 100 * (1 - len(err_idx) / len(preds))\n",
    "    print(f\"Accuracy: {acc:.2f}%  ({len(err_idx)} errores de {len(preds)})\")\n",
    "\n",
    "    # Listar errores\n",
    "    if show_errors and err_idx.size:\n",
    "        print(f\"\\nPrimeros {min(show_errors, len(err_idx))} errores:\")\n",
    "        print(f\"{'file':<40}{'pred':<20}{'true':<20}{'prob':>6}\")\n",
    "        for i in err_idx[:show_errors]:\n",
    "            print(f\"{file_list[i][-40:]:<40}\"\n",
    "                  f\"{idx_to_cls[y_pred[i]]:<20}\"\n",
    "                  f\"{idx_to_cls[y_true[i]]:<20}\"\n",
    "                  f\"{probs[i]:6.2f}\")\n",
    "\n",
    "    # Confusion matrix (hasta 30 clases)\n",
    "    classes = list(idx_to_cls.values())\n",
    "    if len(classes) <= 30:\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"g\", cmap=\"Blues\", cbar=False)\n",
    "        plt.xticks(np.arange(len(classes)) + 0.5, classes, rotation=90)\n",
    "        plt.yticks(np.arange(len(classes)) + 0.5, classes, rotation=0)\n",
    "        plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\"); plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=classes, digits=4))\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "# 3) GUARDAR MODELO + CSV DE CLASES\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Sequence\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "def save_model_and_labels(\n",
    "    out_dir: str | Path,\n",
    "    model: tf.keras.Model,\n",
    "    name: str,\n",
    "    project: str,\n",
    "    accuracy: float,\n",
    "    img_size: Tuple[int, int],\n",
    "    scale: str,\n",
    "    offset: int,\n",
    "    generator: Sequence,\n",
    ") -> Tuple[str, str, str, str]:\n",
    "    \"\"\"\n",
    "    1) SavedModel dir\n",
    "    2) Frozen .pb\n",
    "    3) Arquitecture JSON\n",
    "    4) Pesos HDF5 (.h5)\n",
    "    5) class_dict.csv\n",
    "    \"\"\"\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    acc_tag  = f\"{accuracy:.2f}\"\n",
    "    model_id = f\"{name}-{project}-{acc_tag}\"\n",
    "\n",
    "    # 1) SavedModel\n",
    "    saved_model_dir = out_dir / model_id\n",
    "    tf.saved_model.save(model, str(saved_model_dir))\n",
    "    print(f\"[✓] SavedModel exportado en {saved_model_dir}\")\n",
    "\n",
    "    # 2) Frozen graph .pb\n",
    "    full_model = tf.function(lambda x: model(x))\n",
    "    input_spec  = tf.TensorSpec(\n",
    "        (None, *img_size, model.input_shape[-1]),\n",
    "        model.inputs[0].dtype\n",
    "    )\n",
    "    concrete_fn = full_model.get_concrete_function(input_spec)\n",
    "    frozen_fn   = convert_variables_to_constants_v2(concrete_fn)\n",
    "    frozen_graph_def = frozen_fn.graph.as_graph_def()\n",
    "\n",
    "    pb_path = out_dir / f\"{model_id}.pb\"\n",
    "    tf.io.write_graph(\n",
    "        frozen_graph_def,\n",
    "        str(out_dir),\n",
    "        f\"{model_id}.pb\",\n",
    "        as_text=False\n",
    "    )\n",
    "    print(f\"[✓] Frozen graph .pb guardado en {pb_path}\")\n",
    "\n",
    "    # 4) Pesos HDF5\n",
    "    weights_path = out_dir / f\"{model_id}.h5\"\n",
    "    model.save_weights(str(weights_path), save_format=\"h5\")\n",
    "    print(f\"[✓] Pesos guardados en HDF5 en {weights_path}\")\n",
    "\n",
    "    # 5) CSV de clases\n",
    "    cls_dict = generator.class_indices\n",
    "    df = pd.DataFrame({\n",
    "        \"class_index\": list(cls_dict.values()),\n",
    "        \"class_name\":  list(cls_dict.keys()),\n",
    "        \"height\":      img_size[0],\n",
    "        \"width\":       img_size[1],\n",
    "        \"scale\":       scale,\n",
    "        \"offset\":      offset,\n",
    "    })\n",
    "    csv_path = out_dir / \"class_dict.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"[✓] CSV de clases guardado en {csv_path}\")\n",
    "\n",
    "    return (\n",
    "        str(saved_model_dir),\n",
    "        str(pb_path),\n",
    "        str(arch_path),\n",
    "        str(weights_path),\n",
    "        str(csv_path),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# DATA PREP  · TRIM  · BALANCE\n",
    "# --------------------------------------------------------------------\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import shutil\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "# 1) RECORTE DE MUESTRAS POR CLASE\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "def trim_classes(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    column: str = \"labels\",\n",
    "    max_per_class: int = 300,\n",
    "    min_per_class: int = 10,\n",
    "    seed: int = 123\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Recorta cada clase a `max_per_class` elementos y descarta\n",
    "    las que tengan < `min_per_class`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame  (misma estructura que `df` original)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    keep_blocks: List[pd.DataFrame] = []\n",
    "\n",
    "    for label, group in df.groupby(column):\n",
    "        n = len(group)\n",
    "        if n > max_per_class:\n",
    "            # muestreo estratificado para no perder distribución interna\n",
    "            grp, _ = train_test_split(\n",
    "                group,\n",
    "                train_size=max_per_class,\n",
    "                random_state=seed,\n",
    "                stratify=group[column],\n",
    "            )\n",
    "            keep_blocks.append(grp)\n",
    "        elif n >= min_per_class:\n",
    "            keep_blocks.append(group)\n",
    "        # si n < min_per_class ⇒ se descarta la clase\n",
    "\n",
    "    out = pd.concat(keep_blocks, ignore_index=True)\n",
    "    print(f\"[trim] clases finales: {out[column].nunique()}  \"\n",
    "          f\"(recortadas/eliminadas donde fue necesario)\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "# 2) BALANCEO MEDIANTE AUGMENTACIÓN\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "def balance_dataset(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    column: str = \"labels\",\n",
    "    target_per_class: int = 300,\n",
    "    img_size: Tuple[int, int] = (200, 200),\n",
    "    work_dir: str | Path = \"./\",\n",
    "    seed: int = 123\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Genera imágenes augmentadas para que cada clase tenga exactamente\n",
    "    `target_per_class` ejemplos. Devuelve un nuevo DataFrame con\n",
    "    las rutas a las imágenes originales + las augmentadas.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    work_dir = Path(work_dir)\n",
    "    aug_dir  = work_dir / \"aug\"\n",
    "    if aug_dir.exists():\n",
    "        shutil.rmtree(aug_dir)\n",
    "    aug_dir.mkdir(parents=True)\n",
    "\n",
    "    # generador de Keras para augmentar 1 imagen por iteración\n",
    "    aug_gen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "    )\n",
    "\n",
    "    added: List[dict] = []\n",
    "    for label, group in df.groupby(column):\n",
    "        n_current = len(group)\n",
    "        if n_current >= target_per_class:\n",
    "            continue\n",
    "\n",
    "        n_to_add = target_per_class - n_current\n",
    "        tgt_dir = aug_dir / label\n",
    "        tgt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        flow = aug_gen.flow_from_dataframe(\n",
    "            group,\n",
    "            x_col=\"filepaths\",\n",
    "            y_col=None,\n",
    "            target_size=img_size,\n",
    "            batch_size=1,\n",
    "            shuffle=True,\n",
    "            save_to_dir=tgt_dir,\n",
    "            save_prefix=\"aug\",\n",
    "            color_mode=\"rgb\",\n",
    "            class_mode=None,\n",
    "            seed=seed,\n",
    "        )\n",
    "\n",
    "        for _ in range(n_to_add):\n",
    "            _ = next(flow)  # genera y guarda imagen\n",
    "        new_files = list(tgt_dir.glob(\"*.jpg\"))\n",
    "        added.extend({\"filepaths\": p.as_posix(), column: label} for p in new_files)\n",
    "\n",
    "    print(f\"[balance] imágenes augmentadas creadas: {len(added)}\")\n",
    "    if added:\n",
    "        df_aug = pd.DataFrame(added)\n",
    "        df = pd.concat([df, df_aug], ignore_index=True)\n",
    "\n",
    "    print(f\"[balance] distribución final: {df[column].value_counts().to_dict()}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "# 3) CREACIÓN DE SPLITS train / val / test\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "def build_splits(\n",
    "    root: str | Path,\n",
    "    *,\n",
    "    train_split: float = 0.8,\n",
    "    val_split: float = 0.1,\n",
    "    seed: int = 123\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Lee carpetas `train/`, `val/`, `test/` dentro de `root` y\n",
    "    construye DataFrames estratificados.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_df, val_df, test_df\n",
    "    \"\"\"\n",
    "    root = Path(root)\n",
    "    subdirs = [\"train\", \"val\", \"test\"]\n",
    "    paths, labels = [], []\n",
    "\n",
    "    for sub in subdirs:\n",
    "        for cls_dir in (root / sub).iterdir():\n",
    "            if not cls_dir.is_dir():\n",
    "                continue\n",
    "            for img in cls_dir.iterdir():\n",
    "                if img.is_file():\n",
    "                    paths.append(img.as_posix())\n",
    "                    labels.append(cls_dir.name)\n",
    "\n",
    "    df = pd.DataFrame({\"filepaths\": paths, \"labels\": labels})\n",
    "    train_df, tmp_df = train_test_split(\n",
    "        df,\n",
    "        train_size=train_split,\n",
    "        stratify=df[\"labels\"],\n",
    "        random_state=seed,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    val_rel = val_split / (1 - train_split)\n",
    "    val_df, test_df = train_test_split(\n",
    "        tmp_df,\n",
    "        train_size=val_rel,\n",
    "        stratify=tmp_df[\"labels\"],\n",
    "        random_state=seed,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    n_tr, n_va, n_te = map(len, (train_df, val_df, test_df))\n",
    "    print(f\"[splits] train={n_tr}  val={n_va}  test={n_te}\")\n",
    "    return train_df, val_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[splits] train=389  val=49  test=49\n",
      "[balance] imágenes augmentadas creadas: 0\n",
      "[balance] distribución final: {'1': 389}\n",
      "Found 389 validated image filenames belonging to 1 classes.\n",
      "Found 49 validated image filenames belonging to 1 classes.\n",
      "Found 49 validated image filenames belonging to 1 classes.\n",
      "FlexLRA · start (trainable) – monitoring accuracy ➜ val_loss (threshold=0.9)\n",
      "Ep  |  Loss   TrAcc   VLoss   VAcc   LR ➜ NextLR  Monitor  Δ%  Sec\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000  \n",
      "  1/  1  0.0000  100.00%  0.0000  100.00%  1.0e-03 ➜ 1.0e-03  val_loss   +0.00%  42.2s\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 265ms/step\n",
      "Accuracy: 100.00%  (0 errores de 49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chete\\Anaconda3\\envs\\mi_entorno\\lib\\site-packages\\sklearn\\metrics\\_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqMAAAKzCAYAAAAqSQTzAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAI21JREFUeJzt3Xu0XfO9///X3i5xl8QthNL+kBIkIQmRuKaINHEqhy8nmnPQM1pKS3SEUJVGI4SDInUroQjyc5poFKkTbVpGiVAtDsXQU9fWbbtGKlv2/v3x/dnjpInKJvGOeDzGMMbec33WnO+9/uBpzrXmamhtbW0NAAAUaKweAACAzy4xCgBAGTEKAEAZMQoAQBkxCgBAGTEKAEAZMQoAQBkxCgBAGTEKwBLzPSnA0iZGgeXSww8/nFGjRmXPPffMDjvskIEDB+bUU0/Ns88+u8yOedttt2WvvfbK9ttvn9NOO22p7bdbt2656KKLltr+PuxY3bp1y3nnnbfYx1taWrLbbrulW7dumTp1arv2fdNNN2XChAkfum7EiBEZMWJEu/YNfHatXD0AwN+bPHlyxo8fn5133jnf+c53suGGG+aZZ57JFVdckTvuuCNXXXVVunfvvtSPO3bs2GyxxRY566yzstFGGy21/U6ZMiVdunRZavv7MI2NjZkxY0ZOOOGERR6bM2dOXnrppY+030suuSR9+/b90HVjxoz5SPsHPpucGQWWKw888EDOOOOMDB8+PJMmTcrQoUOz88475+CDD84NN9yQNdZYIyeffPIyOfbrr7+e/v37Z+edd84WW2yx1Pbbs2fPTzRGd9xxxzz99NP57//+70Ueu/XWW7PNNtss0+NvueWW2XLLLZfpMYAVhxgFlitXXnll1l577cWe1evcuXNGjx6dfffdN2+//Xbb9ttuuy3Dhg1Lr1690r9//5x22ml544032h6/6KKLss8++2TWrFkZOnRotttuu+y3336ZNm1akmT27Nnp1q1bkuRHP/pRunXrlueeey6jR4/O3nvvvdAMzz333CKXuK+99toMGjQo22+/fXbbbbd8//vfX2i+v79M/9JLL+Xkk0/OHnvskR122CEHHXRQ7rzzzoWO061bt0yePDnf/e5307dv3/Tq1Svf/va388orr3zoa9i3b9+sv/76uf322xfa/t577+WOO+7Il7/85UWe88c//jHHHntsdtlll3Tv3j277bZbxo0bl7/97W9Jkr333jvPP/98pk2b1vb6TJ06Ndtuu21uuummDBgwILvvvnuefPLJhS7TX3PNNYu8XnPmzMk222yTCy+88EP/FmDFJ0aB5UZra2vuvvvu9OvXL6uvvvpi1wwaNCjHHnts1lprrSTJxRdfnJEjR6ZHjx658MILc8wxx+QXv/hFRowY0RZSSfLyyy/n9NNPz7/+67/m8ssvz6abbprRo0fnqaeeSvfu3TNlypQkyUEHHZQpU6Zkww03XKKZb7311kyYMCGHHXZYrrzyyhxzzDH52c9+lnHjxi12/SuvvJKDDjoo9913X0aOHJmLLrooXbt2zTHHHJPp06cvtPb8889PS0tLzjvvvJx44omZNWtWxo8f/6EzNTY2Zr/99suMGTMW2n7PPffk3XffzV577bXQ9pdeeimHHXZY5s2bl7POOis//vGPs//+++faa6/N1VdfnSSZOHFiNthgg+yxxx4LvT4LFizIpZdemnHjxuX4449f5IzoiBEj0rdv30yYMCFNTU2ZO3duRo8ene222y7f/OY3P/RvAVZ83jMKLDdee+21vPvuu9l0002XaP0bb7yRSy65JAcffPBC71Pceuutc9hhh2Xq1KkZPnx4kmTevHk544wz0q9fvyTJFltskb322iu//vWvc+SRR6Znz55Jki5durT9vCRmz56drl275rDDDktjY2P69u2bNdZYI6+99tpi11911VVpamrK7bffns022yxJsscee+Twww/P2WefnSFDhqSxsbHt7zjzzDPbnvvQQw8tEpgfZPDgwZk8eXIeeeSRbLfddkn+7xnkgQMHZrXVVlto7RNPPJFtttkmF1xwQVvk77rrrrnnnnsyZ86cHHXUUdl2222z6qqrpnPnzou8PkcddVT23HPPxc7R0NCQ8ePH54ADDsg555yTVVddNU1NTZk0aVJWXtl/ggBnRoHlyPsRtmDBgiVa//vf/z7z58/P0KFDF9reu3fvdO3aNbNnz15o+/+OqPffw/nOO+98jImTXXbZJX/+858zbNiwXHzxxXn00UczdOjQ/Nu//dti1993333p1atXW4i+74ADDsjLL7+cP/3pT4ud9/2Z582bt0Rz7bTTTtloo43aLtXPnz8/M2fOzJAhQxZZO2DAgFx33XXp0KFD/ud//ie/+tWvcumll6apqSnz58//0GNtvfXW//DxzTbbLCeddFKmTZuWKVOm5JRTTsnmm2++RH8HsOITo8Byo2PHjllzzTXzwgsvfOCad955J6+//nqStL0vdP31119k3frrr5+33nproW3/+9L/++H7ce+bOXjw4Jx77rlZY401MnHixBx44IEZOHBgbr311sWuf+ONNz5w3iR58803Fzvv+zMv6bwNDQ0ZNGhQ25nUu+66K42Njenfv/8ia1taWvIf//Ef6du3bwYNGpSxY8fm0UcfTYcOHZboWOutt96Hrtl///3ToUOHrLzyyhkwYMAS7Rf4bBCjwHJlwIABmT17dt59993FPj516tT069cvDz74YNZdd90kWeyHel5++eV06tTpY83S0NCwyFnaxZ1JHTJkSK6//vrMnj07P/zhD9OxY8eMGjUqL7744iJr11133Q+cN8nHnvl/Gzx4cJ577rk8/PDDue2227LvvvtmlVVWWWTd5Zdfnquvvjrf/e53c//992fWrFm58MIL07lz56U2y7hx47Laaqtl/fXXz6mnnrrU9gt8+olRYLly5JFH5vXXX8/555+/yGOvvvpqrrjiimy++ebp2bNnevTokVVXXTW33HLLQuvuv//+vPDCC9lxxx0/1ixrrrlm2/tY3/e73/1uoTXHH398jj322CTJ2muvnf333z/f/OY3s2DBgsXez7NPnz558MEHF7l5//Tp07PBBhss1cvXPXv2TNeuXXPLLbfkl7/85WI/RZ/839tpbbnlljnooIOy9tprJ0lefPHFPPHEE2lpaWlb9/7Z5PaaOXNmpk+fntGjR2fMmDG5++67c+ONN36kfQErHu8eB5YrPXv2zHHHHZcf/vCHeeqpp3LggQemU6dOefLJJzNp0qTMnTs3l19+eRoaGtKxY8d8/etfz8SJE7PKKqtk4MCBee6553LBBRdkyy23zLBhwz7WLHvttVeuvfbanHLKKTn44IPbZlhppZXa1uyyyy4ZM2ZMJkyYkN133z1vvvlmJk6cmC222CJf/OIXF9nnEUcckenTp+eII47Isccem06dOuXmm2/Ovffem/Hjx3/k4PsggwYNyjXXXJOOHTt+4A3rd9hhh1x88cW5/PLL07Nnzzz99NO57LLLMn/+/IXeo7rOOuvk0UcfzX333ZcddthhiY7f1NSUMWPGpH///jnwwAOTJPvtt18mTJiQ/v37L/LeWeCzR4wCy52jjz462267bSZPnpwzzzwzr7/+erp06ZLdd989Rx11VDbZZJO2td/61rey/vrr57rrrstNN92Ujh07ZtCgQTn++OM/8PZQS6p///456aSTcu211+aOO+5I9+7dM3HixBx66KFtaw499NA0NzfnxhtvzPXXX5/VVlst/fr1y6hRoxZ7SXyDDTbIDTfckHPPPTdnnHFGmpub88UvfjEXX3xxBg4c+LHmXZzBgwfnyiuvzP777/+BofuNb3wjr732Wq655pr86Ec/ysYbb5x/+qd/SkNDQy677LK88cYbWXfddXPkkUdm/Pjx+drXvparrrpqiY4/duzYzJ07N2PHjm3b9r3vfS+DBw/OKaeckmuuuSYNDQ1L5W8FPp0aWj/uu/cBAOAj8p5RAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKfCpvev+396onAADgH1ltCSvTmVEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyohRAADKiFEAAMqIUQAAyqy8JItOPvnkD11z5plnfuxhAAD4bHFmFACAMg2tra2t1UO019/eq54AAIB/ZLUluv6+hJfp3zd//vzccsstefHFF9PS0pIkaW5uzhNPPJFLLrmk3UMCAPDZ1q4YPeWUU3LXXXelU6dOaW5uzhprrJEnn3wyX/nKV5bReAAArMjaFaN33XVXbrjhhjQ1NeWGG27Iueeem0mTJuWhhx5aVvMBALACa9cHmFpaWvKFL3whX/jCF/LYY48lSQ477LDcf//9y2Q4AABWbO2K0S5duuTZZ59N586d8+qrr+add95Ja2tr5s6du6zmAwBgBdauy/RDhw7N8OHD85//+Z/Zc889c/TRR6dDhw7ZbrvtltV8AACswNp9a6fbb789e+yxR1paWnLOOefk7bffzvHHH5/NNttsWc24CLd2AgBYvi3prZ3cZxQAgKVumdxndMSIEWloaFjsY9dcc017dpUkaWpqyiGHHJJx48Zl5513bvfzAT6NFixYkK9/7fBssknX/GD8WUmSu37z61x0wfl59pmns+mmm+WoY76VgV/ap3hSgGWvXTH698H42muvZcaMGTnkkEPafeAHHnggo0ePzjPPPNPu5wJ8ml168cT87oH7s8kmXZMkjz363zn+W8fku98bkwO+cmAe+sPvc+zRX88666yTPn39jzqwYmtXjB577LGLbBs2bFjOPvvsdh102rRpufDCCzNq1KiMHDmyXc8F+DSbfe89mflfd+RL++zbtu0XM25Prx13zLCDDk6S7LhT7wweMjT/75QbxCiwwmvXrZ0Wp3v37nnkkUfa9ZwBAwbkv/7rvzJ48OCPe3iAT41XX3013z/tuznr7HOz2mqrt21vaVmQ1VdfY6G1jQ2N+fOf/vRJjwjwiWvXmdEXXnhhod+bm5tz6623ZuONN27XQTfYYIN2rQf4tGtpackpo0dlxL8dkW5f/OJCj+09cJ/8+3X/mpl3/CJ77j0wDz/0h8y4/bas27FjzbAAn6B2xejee++90AeYWltbs+666+YHP/jBUh8MYEVy5Y8vS4dVV83ww0Ys8ljPXjvmjLPOziUXT8zp3z8tO+60U/7pwGH53QO+3Q5Y8bUrRu+8886Ffl9ppZWy3nrrZZVVVlmqQwGsaH5+y8/y8ksvZcAuvZMk8+b9LUnyq1/OzK0zZub/2XKr/PTmW9rWj/rO8ene3ReKACu+dr1ndNy4cenatWvbP126dMkqq6ySr371q8tqPoAVws9+PiO/ve93ufve+3P3vfdn8JeHZPCXh+Tue+/P0888na8e+n/y+B//mPfeey8zbr8tv5n1q/yffxlePTbAMvehZ0afe+653HzzzUmSu+++OxMnTlzo8bfffjuPP/74MhkO4LNghx165IRRJ+b4b38zr7/2Wj7/+S/kwh9dmi233Kp6NIBl7kO/gamlpSUjR45MU1NTHnjggey0004LPd6hQ4d85StfyZAhQ5bpoP+bb2ACAFi+LZOvAz311FMzbty4jzrTUiNGAQCWb0sao+16z+iJJ56Y73znO3nqqaeSJBdccEFGjRqVuXPntntAAABoV4yOHTs2b7zxRjr+//e+GzJkSN56662MHz9+WcwGAMAKrl2X6XfZZZfceeedWXPNNdu2vf3229lnn31yzz33LJMBF8dlegCA5dsyuUzf0tKSBQsWLLSttbU1K620Unt2AwAASdoZo7vvvntOOumkPPPMM2lubs4zzzyTk08+Of37919W8wEAsAJr12X6pqamHHfccZkzZ07b14LuuuuuOeecc9K5c+dlNuTfc5keAGD5tkxu7fS+F154IS+//HIWLFiQm2++OdOnT8/vf//79u7mIxOjAADLtyWN0XZ9N/37XnjhhVx55ZX59a9/na222iqjRo36KLsBAOAzboljtKWlJTNmzMhVV12VJ598Mu+9914uu+yy7LbbbstyPgAAVmBL9AGmn/zkJ9lnn31yzjnnZJ999smsWbOy1lprZeutt17W8wEAsAJbojOjZ555ZoYPH57Ro0dn1VVXXdYzAQDwGbFEZ0a/973vZfbs2dljjz1y/vnn58UXX2z7ND0AAHxU7fo0/T333JPrrrsud911VxYsWJAzzjgjQ4cO/cRveu/T9AAAy7dlemun559/Ptdff31++tOfprGxMQcccEBGjx7d3t18ZGIUAGD5tkxj9H3z58/P9OnTc/3112fq1KkfdTftJkYBAJZvn0iMVhGjAADLtyWN0XZ9Nz0AACxNYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDJiFACAMmIUAIAyYhQAgDINra2trdVDAADw2eTMKAAAZcQoAABlxCgAAGXEKAAAZcQoAABlxCgAAGXEKAAAZcQoAABlxCgAAGXEKAAAZcQoAABlxCgAAGXEKAAAZVauHgDgs2bOnDkfuqZPnz6fwCQA9RpaW1tbq4cA+CzZd9998+yzz+aD/vXb0NCQxx577BOeCqCGGAX4hDU1NeXQQw/NyJEjs//++1ePA1BKjAIUeOCBBzJq1KjMnDkzjY3evg98dolRgCI333xzdtttt6y33nrVowCUEaMAAJRxbQgAgDJiFACAMmIU4FPmz3/+c/UIAEuNGAVYjL333jvbb799evXqlV69eqVnz54ZMGBAJkyYkJaWlqVyjBEjRuSiiy5Kkpx22mk57bTTPvQ5v/zlL/O1r33tIx9z6tSp2XvvvT/y8wGWNt/ABPABxo4dm2HDhrX9/vjjj+fwww/P6quvnm9/+9tL9Vinn376Eq17/fXXP/Bm+QCfRmIUYAl169Ytffr0yaOPPpoRI0aka9eumT17dlpbW/Pzn/88TU1NGT9+fB588MGsscYaOeCAA3LMMcdk1VVXTZLcdNNNufTSS9PU1JR999038+bNa9v36NGjkyRnnXVWkuQnP/lJrrvuurzyyiv5/Oc/n1GjRqWxsTFjxoxJc3NzevXqlRkzZqRTp0655JJLMn369Lz11lvp0aNHTj311Gy++eZJkqeeeirf//7388gjj2TTTTfNzjvv/Am/agD/mMv0AEugubk5s2fPzr333pv+/fsnSX7729/mxhtvzPTp09PY2JjDDz88W221VX7zm9/k+uuvz29/+9u2y/D33HNPTj/99IwbNy5z5sxJjx498vDDDy/2WFOnTs3FF1+cs88+Ow888ED+5V/+JUcffXS6deuWsWPHZpNNNsmDDz6YjTbaKOeff35mzZqVq6++OnfddVd69OiRI488Mu+++26am5vzjW98I1tttVXuvffenHfeeZk5c+Yn9poBLAkxCvABxo4dm969e6d3797p169ffvCDH+SII47IV7/61STJ7rvvno022ijrrLNOZs2alfnz5+eEE05Ihw4dsvHGG+e4447L5MmTkyTTp0/Pvvvum379+mXllVfO8OHDs+222y72uNOmTcshhxySXr16pbGxMQcffHAmTZqU1VZbbaF1ra2tufHGG3PCCSdks802S4cOHXLMMcekubk5s2bNyoMPPpi//OUvOfHEE9OhQ4dstdVWOeKII5btiwbQTi7TA3yAMWPGLPSe0b+34YYbtv38/PPPp6mpKX369Gnb1tramubm5rz66qt58cUX071794Wev9lmmy12vy+//HI22WSThbbtuOOOi6xramrKO++8k+OOO26hrxRtbm7O888/n/nz56dTp04LReznPve5D/x7ACqIUYCPqKGhoe3nLl265HOf+1xmzJjRtu3tt9/Oq6++ms6dO6dLly559tlnF3r+X//612y11VaL7HfjjTfOX/7yl4W2nX/++TnggAMW2tapU6d06NAhkyZNSs+ePdu2/+lPf8pGG22Uxx57LE1NTZk7d27WXHPNtmMCLE9cpgdYCvbaa6/MnTs3V1xxRebPn58333wzJ510UkaOHJmGhob88z//c2bOnJlf/epXee+99zJt2rT84Q9/WOy+hg0blilTpuShhx5KS0tLfvrTn2by5Mlt8Tlv3ry89957aWxszEEHHZRzzz03f/3rX9PS0pJp06ZlyJAhefrpp9OrV698/vOfz7hx4zJv3rw8/fTTmTRp0if8ygD8Y2IUYClYa621cvXVV2f27NnZfffd86UvfSmNjY255JJLkiQ77bRTzj777Jx11lnp3bt3fvGLX7R9EOrvDR06NN/61rcyatSo9O7dO1OmTMmPf/zjdO7cOX369Ml6662XPn365PHHH89JJ52UHj16ZPjw4endu3euvvrqXHjhhdl2222z0kor5fLLL89LL72UXXfdNf/+7/+egQMHfpIvC8CHamh1wzoAAIo4MwoAQBkxCgBAGTEKAEAZMQoAQBkxCgBAGTEKAEAZMQoAQBkxCgBAGTEKAEAZMQoAQBkxCgBAGTEKAECZ/w/VnGIykV5ByAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     1.0000    1.0000    1.0000        49\n",
      "\n",
      "    accuracy                         1.0000        49\n",
      "   macro avg     1.0000    1.0000    1.0000        49\n",
      "weighted avg     1.0000    1.0000    1.0000        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] SavedModel exportado en C:\\Users\\chete\\Desktop\\TFG\\TEEST\\EffNetB0-MyClassification-100.00\n",
      "[✓] Frozen graph .pb guardado en C:\\Users\\chete\\Desktop\\TFG\\TEEST\\EffNetB0-MyClassification-100.00.pb\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 108\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# ---- 8. Guardado opcional -------------------------------------------\u001b[39;00m\n\u001b[0;32m    101\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_gen, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m    102\u001b[0m (\n\u001b[0;32m    103\u001b[0m     saved_model_dir,\n\u001b[0;32m    104\u001b[0m     pb_path,\n\u001b[0;32m    105\u001b[0m     arch_path,\n\u001b[0;32m    106\u001b[0m     weights_path,\n\u001b[0;32m    107\u001b[0m     csv_path\n\u001b[1;32m--> 108\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43msave_model_and_labels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEffNetB0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMyClassification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_acc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1-0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✔ Proceso finalizado.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  • SavedModel dir      : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msaved_model_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 168\u001b[0m, in \u001b[0;36msave_model_and_labels\u001b[1;34m(out_dir, model, name, project, accuracy, img_size, scale, offset, generator)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# 3) Arquitectura JSON\u001b[39;00m\n\u001b[0;32m    167\u001b[0m arch_path \u001b[38;5;241m=\u001b[39m out_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_architecture.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 168\u001b[0m arch_json \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m arch_path\u001b[38;5;241m.\u001b[39mwrite_text(arch_json)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[✓] Arquitectura JSON guardada en \u001b[39m\u001b[38;5;132;01m{\u001b[39;00march_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\chete\\Anaconda3\\envs\\mi_entorno\\lib\\site-packages\\keras\\engine\\training.py:3087\u001b[0m, in \u001b[0;36mModel.to_json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a JSON string containing the network configuration.\u001b[39;00m\n\u001b[0;32m   3075\u001b[0m \n\u001b[0;32m   3076\u001b[0m \u001b[38;5;124;03mTo load a network from a JSON save file, use\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;124;03m    A JSON string.\u001b[39;00m\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3086\u001b[0m model_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_updated_config()\n\u001b[1;32m-> 3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mdumps(\n\u001b[0;32m   3088\u001b[0m     model_config, default\u001b[38;5;241m=\u001b[39mjson_utils\u001b[38;5;241m.\u001b[39mget_json_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   3089\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\chete\\Anaconda3\\envs\\mi_entorno\\lib\\json\\__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chete\\Anaconda3\\envs\\mi_entorno\\lib\\json\\encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[1;32mc:\\Users\\chete\\Anaconda3\\envs\\mi_entorno\\lib\\json\\encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[0;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chete\\Anaconda3\\envs\\mi_entorno\\lib\\site-packages\\keras\\saving\\saved_model\\json_utils.py:221\u001b[0m, in \u001b[0;36mget_json_type\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, enum\u001b[38;5;241m.\u001b[39mEnum):\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to serialize \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to JSON. Unrecognized type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# MAIN – entrenamiento y evaluación end‑to‑end\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# ---- 1. Rutas y parámetros globales ---------------------------------\n",
    "base_dir      = Path(r\"C:/Users/chete/Desktop/TFG/Contador Datos/30Classification\")\n",
    "#base_dir      = Path(r\"C:\\Users\\chete\\Desktop\\TFG\\TEEST\")\n",
    "batch_size    = 32       # normalmente 32\n",
    "img_size      = (200, 200)\n",
    "max_per_class = 300\n",
    "min_per_class = 10\n",
    "epochs        = 10          # poner 1 para pruebas rápidas\n",
    "seed          = 123\n",
    "\n",
    "# ---- 2. Splits + balanceo ------------------------------------------\n",
    "train_df, val_df, test_df = build_splits(base_dir, seed=seed)\n",
    "train_df = balance_dataset(\n",
    "    train_df,\n",
    "    target_per_class=max_per_class,\n",
    "    img_size=img_size,\n",
    "    work_dir=base_dir,\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "# ---- 3. Generadores de imágenes -------------------------------------\n",
    "def identity(img):           # EfficientNetB0 acepta [0‑255]\n",
    "    return img\n",
    "\n",
    "def make_gen(df, shuffle: bool) -> tf.keras.utils.Sequence:\n",
    "    return ImageDataGenerator(preprocessing_function=identity).flow_from_dataframe(\n",
    "        df,\n",
    "        x_col=\"filepaths\",\n",
    "        y_col=\"labels\",\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        color_mode=\"rgb\",\n",
    "        shuffle=shuffle,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "train_gen = make_gen(train_df, shuffle=True)\n",
    "val_gen   = make_gen(val_df,   shuffle=True)\n",
    "test_gen  = make_gen(test_df,  shuffle=False)\n",
    "\n",
    "class_names = list(train_gen.class_indices)\n",
    "n_classes   = len(class_names)\n",
    "steps_per_epoch = int(np.ceil(len(train_gen.labels) / batch_size))\n",
    "\n",
    "# ---- 4. Construcción del modelo -------------------------------------\n",
    "base = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(*img_size, 3),\n",
    "    pooling=\"max\",\n",
    ")\n",
    "x = BatchNormalization()(base.output)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(n_classes, activation=\"softmax\")(x)\n",
    "model = Model(base.input, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adamax(learning_rate=1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# ---- 5. Callback de adaptación del LR --------------------------------\n",
    "lr_cb = FlexLRA(\n",
    "    model=model,                # tu Keras model\n",
    "    base_model=base,            # el EfficientNetB0 (o None)\n",
    "    patience=2,                 # epochs sin mejora antes de recortar LR\n",
    "    stop_patience=3,            # recortes sin mejora antes de parar\n",
    "    threshold=0.9,              # pasar a vigilar val_loss\n",
    "    factor=0.5,                 # lr *= factor\n",
    "    dwell=True,                 # restaurar pesos si no mejora\n",
    "    batches=steps_per_epoch,    # nº de batches por epoch\n",
    "    initial_epoch=0,            # epoch de inicio (para mostrar)\n",
    "    epochs=epochs,              # total epochs planificadas\n",
    "    ask_epoch=None,             # o un entero para consulta interactiva\n",
    "    csv_path=None,              # o ruta para CSV de log\n",
    "    verbose=1,                  # 1 muestra mensajes, 0 silencio\n",
    ")\n",
    "\n",
    "# ---- 6. Entrenamiento ------------------------------------------------\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=[lr_cb],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# ---- 7. Gráficas y métricas -----------------------------------------\n",
    "plot_history(history)\n",
    "test_gen.reset()\n",
    "preds = model.predict(test_gen, verbose=1)\n",
    "evaluate_predictions(test_gen, preds, show_errors=5)\n",
    "\n",
    "# ---- 8. Guardado opcional -------------------------------------------\n",
    "test_acc = model.evaluate(test_gen, verbose=0)[1] * 100\n",
    "saved_model_dir, pb_path, weights_path, csv_path = save_model_and_labels(\n",
    "    out_dir    = base_dir,\n",
    "    model      = model,\n",
    "    name       = \"EffNetB0\",\n",
    "    project    = \"MyClassification\",\n",
    "    accuracy   = test_acc,\n",
    "    img_size   = img_size,\n",
    "    scale      = \"1-0\",\n",
    "    offset     = 0,\n",
    "    generator  = train_gen,\n",
    ")\n",
    "\n",
    "print(\"✔ Proceso finalizado.\")\n",
    "print(f\"  • SavedModel dir : {saved_model_dir}\")\n",
    "print(f\"  • Frozen .pb     : {pb_path}\")\n",
    "print(f\"  • Pesos .h5      : {weights_path}\")\n",
    "print(f\"  • CSV de clases  : {csv_path}\")\n",
    "# --------------------------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_entorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
